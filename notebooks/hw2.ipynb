{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2364fc63-683d-44cf-bccd-b29c2adec0fd",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "Bradley Thompson - CS 510 Large Language Models PDX Winter 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce174414-cc4e-40b3-a26a-ef1ca2f4cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "MODELS = (\n",
    "    \"bigscience/bloom-560m\",\n",
    "    \"bigscience/bloom-1b1\",\n",
    "    \"bigscience/bloom-1b7\",\n",
    "    \"bigscience/bloomz-560m\",\n",
    "    \"bigscience/bloomz-1b1\",\n",
    "    \"bigscience/bloomz-1b7\",\n",
    ")\n",
    "ID_TO_LABEL = {\n",
    "    0: \"negative\",\n",
    "    1: \"neutral\",\n",
    "    2: \"positive\",\n",
    "}\n",
    "LABEL_TO_ID = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"positive\": 2\n",
    "}\n",
    "\n",
    "DEFAULT_PROMPT = \"Asign any label of these options ['positive', 'negative', 'neutral'] to the following text: '%s'. Label: \"\n",
    "\n",
    "model_name = MODELS[0]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba1cd0c-c9ca-48e0-ad44-0fc713b4a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'it looks like a beautiful night to throw myself off the Brooklyn Bridge ---@Tim_Hecht ',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\")\n",
    "sample = 2\n",
    "negative_texts = [ sample for sample in dataset[\"train\"] if sample[\"label\"] == LABEL_TO_ID[\"negative\"] ]\n",
    "#text = dataset[\"train\"][sample][\"text\"]\n",
    "text = negative_texts[2]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ea228c-026c-45ee-b3c1-9ab45fe6c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  okay i\\u2019m sorry but TAYLOR SWIFT LOOKS NOTHING LIKE JACKIE O SO STOP COMPARING THE TWO. c\\u2019mon America aren\\u2019t you sick of her yet? (sorry) \n",
      "Actual:  negative\n",
      "Classification:   'Positive', '\n",
      "Input:  The tragedy of only thinking up hilarious tweets for the Summer Olympics now is that in four years there may be no place for them. \n",
      "Actual:  negative\n",
      "Classification:   'Positive', Label\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "NEW_TOKENS = 5\n",
    "\n",
    "config = {\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"max_new_tokens\": NEW_TOKENS,\n",
    "    \"use_cache\": False,\n",
    "    # \"do_sample\": True,\n",
    "    # \"top_k\": 2,\n",
    "}\n",
    "\n",
    "def output_with_classification(prompt: str) -> str:\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    gen_config: GenerationConfig = GenerationConfig.from_dict(config)\n",
    "    output = model.generate(inputs, gen_config)[0]\n",
    "    return tokenizer.decode(output[-NEW_TOKENS:])\n",
    "\n",
    "for sample in negative_texts[:2]:\n",
    "    input = sample[\"text\"]\n",
    "    print(\"Input: \", input)\n",
    "    print(\"Actual: \", ID_TO_LABEL[sample[\"label\"]])\n",
    "    print(\"Classification: \", output_with_classification(DEFAULT_PROMPT % input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f76fb-41c2-4512-94f8-651d8eb13f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
