{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2364fc63-683d-44cf-bccd-b29c2adec0fd",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "Bradley Thompson - CS 510 Large Language Models PDX Winter 2024\n",
    "\n",
    "## Experimental Setting 1\n",
    "To start, I simply tried to set up my test bed for model performance. I missed the class where we disussed breaking down the model output\n",
    "by getting the log probability of the result tokens, and while it makes sense in theory, I don't know how to do it in practice. So, I instead\n",
    "decided to come up with a simple approach for checking on the generated output labels, by simply checking for substring presence and throwing out samples where a category can't be found. This is sub-par becuase it doesn't account for cases where multiple labels are selected in rambling output, and because it doesn't account for malformed output which might resemble a category option closely. I tried to remediate this at least slightly be limiting the number of new tokens generated, so that multiple labels were unlikely to be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce174414-cc4e-40b3-a26a-ef1ca2f4cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "MODELS = (\n",
    "    \"bigscience/bloom-560m\",\n",
    "    \"bigscience/bloom-1b1\",\n",
    "    \"bigscience/bloom-1b7\",\n",
    "    \"bigscience/bloomz-560m\",\n",
    "    \"bigscience/bloomz-1b1\",\n",
    "    \"bigscience/bloomz-1b7\",\n",
    ")\n",
    "POSITIVE=\"positive\"\n",
    "NEUTRAL=\"neutral\"\n",
    "NEGATIVE=\"negative\"\n",
    "LABEL_TO_ID={\n",
    "    0: NEGATIVE,\n",
    "    1: NEUTRAL,\n",
    "    2: POSITIVE,\n",
    "}\n",
    "\n",
    "DEFAULT_PROMPT = \"Asign any label of these options ['positive', 'negative', 'neutral'] to the following text: '%s'. Label: \"\n",
    "\n",
    "model_name = MODELS[0]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba1cd0c-c9ca-48e0-ad44-0fc713b4a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'it looks like a beautiful night to throw myself off the Brooklyn Bridge ---@Tim_Hecht ',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\")\n",
    "sample = 2\n",
    "negative_texts = [ sample for sample in dataset[\"train\"] if LABEL_TO_ID[sample[\"label\"]] == NEGATIVE ]\n",
    "#text = dataset[\"train\"][sample][\"text\"]\n",
    "text = negative_texts[2]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8144dacb-963d-48ea-b5e2-b1b05f931ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['okay i\\\\u2019m sorry but TAYLOR SWIFT LOOKS NOTHING LIKE JACKIE O SO STOP COMPARING THE TWO. c\\\\u2019mon America aren\\\\u2019t you sick of her yet? (sorry) ',\n",
       "  '@user the DC comics site has Batman 44 releases on the 9th but its out now? ',\n",
       "  '\"Frank Gaffrey\\\\u002c Cliff May\\\\u002c Steve Emerson: Brilliant. \\\\\"\"\"\"Looming Threats: Iran\\\\u002c Hezbollah Hamas\\\\\"\"\"\" is the best #cufidc session I\\\\u2019ve had thus far.\" ',\n",
       "  'The tragedy of only thinking up hilarious tweets for the Summer Olympics now is that in four years there may be no place for them. ',\n",
       "  '\"Oliseh meets with Victor Moses in London: Super Eagles coach, Sunday Oliseh, has met with Nigeria and Chelsea ... ',\n",
       "  '\"People always forget the fact that Shawn achieved so much in the age of 16 like his 1st single, EP and FIRST album ALL went #1 on charts\" ',\n",
       "  'it looks like a beautiful night to throw myself off the Brooklyn Bridge ---@Tim_Hecht ',\n",
       "  '@user WAIT WHAT?!?! SCOTUS makes laws!?!? since when? have i been lied to my entire 8th grade year about gov? (sarcasm intended) ',\n",
       "  '\"Winnipeg Sun: \"\"But make no mistake: Janet Jackson played to win. And did.\"\" #UnbreakableWinnipeg #UnbreakableWorldTour ',\n",
       "  'I wanna go to the studio with Ulysses n them tomorrow\\\\u002cbut i cant. #BARS '],\n",
       " 'label': [0, 1, 2, 0, 1, 2, 0, 1, 2, 0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ea228c-026c-45ee-b3c1-9ab45fe6c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      " 'positive', '\n",
      "Step 0: categorized 1 / 1839 | pos 1 ; neg 0 ; neut 0\n",
      "neutral\n",
      " @user the dc com\n",
      "Step 1: categorized 1 / 1839 | pos 1 ; neg 0 ; neut 0\n",
      "positive\n",
      " 'positive', '\n",
      "Step 2: categorized 2 / 1839 | pos 2 ; neg 0 ; neut 0\n",
      "negative\n",
      " 'positive', label\n",
      "Step 3: categorized 3 / 1839 | pos 3 ; neg 0 ; neut 0\n",
      "neutral\n",
      " 'positive', '\n",
      "Step 4: categorized 4 / 1839 | pos 4 ; neg 0 ; neut 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "NEW_TOKENS = 5\n",
    "\n",
    "config = {\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"max_new_tokens\": NEW_TOKENS,\n",
    "    \"use_cache\": False,\n",
    "    # \"do_sample\": True,\n",
    "    # \"top_k\": 2,\n",
    "}\n",
    "\n",
    "def output_raw_classification(prompt: str) -> str:\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    gen_config: GenerationConfig = GenerationConfig.from_dict(config)\n",
    "    output = model.generate(inputs, gen_config)[0]\n",
    "    return tokenizer.decode(output[-NEW_TOKENS:])\n",
    "\n",
    "target_dataset = dataset[\"train\"]\n",
    "\n",
    "total_count = len(target_dataset)\n",
    "p = 0\n",
    "tp = 0\n",
    "neg = 0\n",
    "tneg = 0\n",
    "neut = 0\n",
    "tneut = 0\n",
    "for i, sample in enumerate(target_dataset):\n",
    "    if i == 5: # TODO REMOVE\n",
    "        break\n",
    "    input = sample[\"text\"]\n",
    "    label = sample[\"label\"]\n",
    "    print(LABEL_TO_ID[label])\n",
    "    output = output_raw_classification(DEFAULT_PROMPT % input).lower()\n",
    "    print(output)\n",
    "    if POSITIVE in output:\n",
    "        p += 1\n",
    "        if LABEL_TO_ID[label] == POSITIVE:\n",
    "            tp += 1\n",
    "    elif NEGATIVE in output:\n",
    "        neg += 1\n",
    "        if LABEL_TO_ID[label] == NEGATIVE:\n",
    "            tneg += 1\n",
    "    elif NEUTRAL in output:\n",
    "        neut += 1\n",
    "        if LABEL_TO_ID[label] == NEUTRAL:\n",
    "            tneut += 1\n",
    "    print(f\"Step {i}: categorized {p + neg + neut} / {total_count} | pos {p} ; neg {neg} ; neut {neut}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7f76fb-41c2-4512-94f8-651d8eb13f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos prec 0.25 pos rec 1.0\n"
     ]
    }
   ],
   "source": [
    "fp = p - tp\n",
    "fneg = neg - tneg\n",
    "fneut = neut - tneut\n",
    "p_precision = tp / p\n",
    "p_recall = tp / len([ label for label in target_dataset[:5][\"label\"] if LABEL_TO_ID[label] == POSITIVE ])\n",
    "print(f\"pos prec {p_precision} pos rec {p_recall}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
